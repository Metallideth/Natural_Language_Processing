{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import math\n",
    "from openpyxl import Workbook\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../inference/25-02-2024_1324_antikey_output.pkl','rb') as file:\n",
    "    impact_output = pickle.load(file)\n",
    "with open('../Data/index_label_mapping.pkl','rb') as file:\n",
    "    index_label_mapping = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669785"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(impact_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Role': ['GOVERNANCE RISK COMPLIANCE',\n",
       "  'INFORMATION SECURITY',\n",
       "  'IT GENERAL',\n",
       "  'NETWORKING',\n",
       "  'NON-ICP',\n",
       "  'SYSTEMS'],\n",
       " 'Function': ['ENGINEERING',\n",
       "  'IT',\n",
       "  'NON-ICP',\n",
       "  'PROCUREMENT',\n",
       "  'RISK/LEGAL/COMPLIANCE'],\n",
       " 'Level': ['C-LEVEL',\n",
       "  'CONTRIBUTOR',\n",
       "  'DIRECTOR',\n",
       "  'EXECUTIVE',\n",
       "  'MANAGER',\n",
       "  'UNKNOWN']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = {x.replace(\"Job \",\"\"):list(index_label_mapping[x].values()) for x in index_label_mapping}\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sequence': 'IT DIRECTOR',\n",
       " 'Role': [{'Anti-Prediction': 'GOVERNANCE RISK COMPLIANCE',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.13329343497753143,\n",
       "    'DIRECTOR': 0.8667065501213074},\n",
       "   'Token_Rank': {'IT': 2, 'DIRECTOR': 1},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 0.7029886245727539,\n",
       "    'DIRECTOR': 4.571004390716553},\n",
       "   'Token_Marginal_Score_Raw': {'IT': 0.7029886245727539,\n",
       "    'DIRECTOR': 4.571004390716553}},\n",
       "  {'Anti-Prediction': 'INFORMATION SECURITY',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.0, 'DIRECTOR': 1.0},\n",
       "   'Token_Rank': {'IT': 2, 'DIRECTOR': 1},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 0.0, 'DIRECTOR': 4.458810329437256},\n",
       "   'Token_Marginal_Score_Raw': {'IT': -0.7214062213897705,\n",
       "    'DIRECTOR': 4.458810329437256}},\n",
       "  {'Anti-Prediction': 'IT GENERAL',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.33253294229507446,\n",
       "    'DIRECTOR': 0.6674670577049255},\n",
       "   'Token_Rank': {'IT': 2, 'DIRECTOR': 1},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 3.361983299255371,\n",
       "    'DIRECTOR': 6.74824333190918},\n",
       "   'Token_Marginal_Score_Raw': {'IT': 3.361983299255371,\n",
       "    'DIRECTOR': 6.74824333190918}},\n",
       "  {'Anti-Prediction': 'NON-ICP',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.927590548992157,\n",
       "    'DIRECTOR': 0.07240938395261765},\n",
       "   'Token_Rank': {'IT': 1, 'DIRECTOR': 2},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 8.24742603302002,\n",
       "    'DIRECTOR': 0.6438088417053223},\n",
       "   'Token_Marginal_Score_Raw': {'IT': 8.24742603302002,\n",
       "    'DIRECTOR': 0.6438088417053223}},\n",
       "  {'Anti-Prediction': 'SYSTEMS',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.3926181197166443,\n",
       "    'DIRECTOR': 0.6073818802833557},\n",
       "   'Token_Rank': {'IT': 2, 'DIRECTOR': 1},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 1.2639806270599365,\n",
       "    'DIRECTOR': 1.95538330078125},\n",
       "   'Token_Marginal_Score_Raw': {'IT': 1.2639806270599365,\n",
       "    'DIRECTOR': 1.95538330078125}}],\n",
       " 'Function': [{'Anti-Prediction': 'ENGINEERING',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.2290356457233429,\n",
       "    'DIRECTOR': 0.7709643840789795},\n",
       "   'Token_Rank': {'IT': 2, 'DIRECTOR': 1},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 0.611567497253418,\n",
       "    'DIRECTOR': 2.058617353439331},\n",
       "   'Token_Marginal_Score_Raw': {'IT': 0.611567497253418,\n",
       "    'DIRECTOR': 2.058617353439331}},\n",
       "  {'Anti-Prediction': 'NON-ICP',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.7307974100112915,\n",
       "    'DIRECTOR': 0.2692025601863861},\n",
       "   'Token_Rank': {'IT': 1, 'DIRECTOR': 2},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 10.937780380249023,\n",
       "    'DIRECTOR': 4.029130935668945},\n",
       "   'Token_Marginal_Score_Raw': {'IT': 10.937780380249023,\n",
       "    'DIRECTOR': 4.029130935668945}},\n",
       "  {'Anti-Prediction': 'PROCUREMENT',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.41413554549217224,\n",
       "    'DIRECTOR': 0.5858644843101501},\n",
       "   'Token_Rank': {'IT': 2, 'DIRECTOR': 1},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 3.732133388519287,\n",
       "    'DIRECTOR': 5.279731273651123},\n",
       "   'Token_Marginal_Score_Raw': {'IT': 3.732133388519287,\n",
       "    'DIRECTOR': 5.279731273651123}},\n",
       "  {'Anti-Prediction': 'RISK/LEGAL/COMPLIANCE',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.41550543904304504,\n",
       "    'DIRECTOR': 0.5844945311546326},\n",
       "   'Token_Rank': {'IT': 2, 'DIRECTOR': 1},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 3.7925939559936523,\n",
       "    'DIRECTOR': 5.33506965637207},\n",
       "   'Token_Marginal_Score_Raw': {'IT': 3.7925939559936523,\n",
       "    'DIRECTOR': 5.33506965637207}}],\n",
       " 'Level': [{'Anti-Prediction': 'C-LEVEL',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.5286777019500732,\n",
       "    'DIRECTOR': 0.471322238445282},\n",
       "   'Token_Rank': {'IT': 1, 'DIRECTOR': 2},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 2.7890303134918213,\n",
       "    'DIRECTOR': 2.486452579498291},\n",
       "   'Token_Marginal_Score_Raw': {'IT': 2.7890303134918213,\n",
       "    'DIRECTOR': 2.486452579498291}},\n",
       "  {'Anti-Prediction': 'CONTRIBUTOR',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.0, 'DIRECTOR': 1.0},\n",
       "   'Token_Rank': {'IT': 2, 'DIRECTOR': 1},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 0.0, 'DIRECTOR': 4.572686672210693},\n",
       "   'Token_Marginal_Score_Raw': {'IT': -3.185157060623169,\n",
       "    'DIRECTOR': 4.572686672210693}},\n",
       "  {'Anti-Prediction': 'EXECUTIVE',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': nan, 'DIRECTOR': nan},\n",
       "   'Token_Rank': {'IT': 2, 'DIRECTOR': 1},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 0.0, 'DIRECTOR': 0.0},\n",
       "   'Token_Marginal_Score_Raw': {'IT': -0.8801902532577515,\n",
       "    'DIRECTOR': -0.5991784334182739}},\n",
       "  {'Anti-Prediction': 'MANAGER',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.40151524543762207,\n",
       "    'DIRECTOR': 0.5984847545623779},\n",
       "   'Token_Rank': {'IT': 2, 'DIRECTOR': 1},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 2.335191488265991,\n",
       "    'DIRECTOR': 3.480755567550659},\n",
       "   'Token_Marginal_Score_Raw': {'IT': 2.335191488265991,\n",
       "    'DIRECTOR': 3.480755567550659}},\n",
       "  {'Anti-Prediction': 'UNKNOWN',\n",
       "   'Distinct_Tokens': ['IT', 'DIRECTOR'],\n",
       "   'Token_Importance': {'IT': 0.44434991478919983,\n",
       "    'DIRECTOR': 0.5556501150131226},\n",
       "   'Token_Rank': {'IT': 2, 'DIRECTOR': 1},\n",
       "   'Token_Marginal_Score_Positive': {'IT': 4.43302059173584,\n",
       "    'DIRECTOR': 5.543397903442383},\n",
       "   'Token_Marginal_Score_Raw': {'IT': 4.43302059173584,\n",
       "    'DIRECTOR': 5.543397903442383}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impact_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize compilation dictionary - we'll have entries for role, function, and level, which will lead to\n",
    "# entries for each potential output category, which will lead to entries for every individual word with:\n",
    "# 1. Average token importance\n",
    "# 2. Average number of unique tokens in sequence\n",
    "# 3. Average marginal score (positive) - keyword\n",
    "# 4. Average marginal score (raw)\n",
    "# 5. Average marginal score (negative) - anti-keyword\n",
    "# 6. Average token score rank\n",
    "# For 1-6 we'll first need to just record every entry in the structure, then we can run through and take the average\n",
    "keyword_dict_running = {**unique_values}\n",
    "for x in keyword_dict_running:\n",
    "    keyword_dict_running[x] = {}\n",
    "    for y in unique_values[x]:\n",
    "        keyword_dict_running[x][y] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 669785/669785 [03:04<00:00, 3625.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run through the data\n",
    "# tqdm(enumerate(data_loader,0),total=len(data_loader))\n",
    "for _,sequence in tqdm(enumerate(impact_output,0),total=len(impact_output)):\n",
    "    for key in keyword_dict_running:\n",
    "        this_sequence_info = sequence[key]\n",
    "        for anti_prediction in this_sequence_info:\n",
    "            this_anti_prediction = anti_prediction['Anti-Prediction']\n",
    "            this_tokens = anti_prediction['Distinct_Tokens']\n",
    "            this_unique_tokens_count = len(this_tokens)\n",
    "            for token in this_tokens:\n",
    "                # If not already present in the keyword_dict_running, add it\n",
    "                if token not in keyword_dict_running[key][this_anti_prediction]:\n",
    "                    keyword_dict_running[key][this_anti_prediction][token] = defaultdict(list)\n",
    "                # Append to lists the abovementioned metrics\n",
    "                token_importance = anti_prediction['Token_Importance'][token]\n",
    "                marginal_score_positive = anti_prediction['Token_Marginal_Score_Positive'][token]\n",
    "                raw_score = anti_prediction['Token_Marginal_Score_Raw'][token]\n",
    "                token_rank = anti_prediction['Token_Rank'][token] \n",
    "                if math.isnan(token_importance):\n",
    "                    token_importance = 0\n",
    "                keyword_dict_running[key][this_anti_prediction][token]['Token_Importance'].append(token_importance)\n",
    "                keyword_dict_running[key][this_anti_prediction][token]['Unique_Tokens_Count'].append(this_unique_tokens_count)\n",
    "                keyword_dict_running[key][this_anti_prediction][token]['Marginal_Score_Positive'].append(marginal_score_positive)\n",
    "                keyword_dict_running[key][this_anti_prediction][token]['Marginal_Score_Raw'].append(raw_score)\n",
    "                keyword_dict_running[key][this_anti_prediction][token]['Marginal_Score_Negative'].append(min(raw_score,0))\n",
    "                keyword_dict_running[key][this_anti_prediction][token]['Token_Rank'].append(token_rank)\n",
    "                keyword_dict_running[key][this_anti_prediction][token]['Token_Occurrences'].append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_dict_average = {**unique_values}\n",
    "for x in keyword_dict_average:\n",
    "    keyword_dict_average[x] = {}\n",
    "    for y in unique_values[x]:\n",
    "        keyword_dict_average[x][y] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24531it [00:03, 6765.95it/s] \n",
      "20261it [00:02, 9743.35it/s] \n",
      "23633it [00:02, 8495.86it/s] \n",
      "21160it [00:02, 10190.44it/s]\n",
      "17162it [00:02, 8007.79it/s] \n",
      "24324it [00:02, 9410.82it/s] \n",
      "23244it [00:02, 9123.02it/s] \n",
      "12830it [00:00, 17121.84it/s]\n",
      "19460it [00:02, 8536.17it/s] \n",
      "24738it [00:02, 8701.63it/s] \n",
      "24759it [00:02, 8980.52it/s] \n",
      "23014it [00:02, 9317.69it/s] \n",
      "18898it [00:01, 9754.22it/s] \n",
      "21654it [00:02, 10037.73it/s]\n",
      "21803it [00:02, 9436.58it/s] \n",
      "21216it [00:02, 10019.90it/s]\n",
      "24581it [00:02, 9223.18it/s] \n"
     ]
    }
   ],
   "source": [
    "# Now we run through the above dictionary and calculate the averages for each token and underlying list\n",
    "for key in keyword_dict_running:\n",
    "    for prediction in keyword_dict_running[key]:\n",
    "        keyword_dict_average[key][prediction] = defaultdict(list)\n",
    "        for _,token in tqdm(enumerate(keyword_dict_running[key][prediction])):\n",
    "            keyword_dict_average[key][prediction]['Token'].append(token)\n",
    "            keyword_dict_average[key][prediction]['Avg_Token_Importance'].append(np.array(keyword_dict_running[key][prediction][token]['Token_Importance']).mean())\n",
    "            keyword_dict_average[key][prediction]['Avg_Unique_Tokens_Count'].append(np.array(keyword_dict_running[key][prediction][token]['Unique_Tokens_Count']).mean())\n",
    "            keyword_dict_average[key][prediction]['Avg_Marginal_Score_Positive'].append(np.array(keyword_dict_running[key][prediction][token]['Marginal_Score_Positive']).mean())\n",
    "            keyword_dict_average[key][prediction]['Avg_Marginal_Score_Raw'].append(np.array(keyword_dict_running[key][prediction][token]['Marginal_Score_Raw']).mean())\n",
    "            keyword_dict_average[key][prediction]['Avg_Marginal_Score_Negative'].append(np.array(keyword_dict_running[key][prediction][token]['Marginal_Score_Negative']).mean())\n",
    "            keyword_dict_average[key][prediction]['Avg_Token_Rank'].append(np.array(keyword_dict_running[key][prediction][token]['Token_Rank']).mean())\n",
    "            keyword_dict_average[key][prediction]['Total_Token_Occurrences'].append(np.array(keyword_dict_running[key][prediction][token]['Token_Occurrences']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a table for each output and possible value for that output. Let's start with a new dictionary to house it\n",
    "keyword_table_dict = {}\n",
    "for x in unique_values:\n",
    "    keyword_table_dict[x] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keyword_dict_average:\n",
    "    for output in keyword_dict_average[key]:\n",
    "        keyword_table_dict[key][output] = pd.DataFrame.from_dict(keyword_dict_average[key][output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write tables to excel - filter out values with less than 100 total token occurrences\n",
    "writer_keyword = pd.ExcelWriter('../inference/impact_output_antikeyword.xlsx',engine = 'xlsxwriter')\n",
    "for key in keyword_table_dict:\n",
    "    for output in keyword_table_dict[key]:\n",
    "        this_df = keyword_table_dict[key][output] \n",
    "        this_df[this_df.Total_Token_Occurrences >= 100].sort_values(by = 'Avg_Token_Importance',ascending=False).to_excel(\n",
    "            writer_keyword,sheet_name='{}_{}'.format(key.replace('/',''),output.replace('/','')),index = False)\n",
    "writer_keyword.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netskope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
